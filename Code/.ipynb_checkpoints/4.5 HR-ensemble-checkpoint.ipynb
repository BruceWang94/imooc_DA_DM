{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] += os.pathsep + '/usr/local/Cellar/graphviz/2.40.1/bin'\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sl: satisfaction_level --- False:MinMaxScaler; True:StandardScaler\n",
    "# le: last_evaluation --- False:MinMaxScaler; True:StandardScaler\n",
    "# npr: number_project --- False:MinMaxScaler; True:StandardScaler\n",
    "# amh: average_monthly_hours --- False:MinMaxScaler; True:StandardScaler\n",
    "# tsc: time_spend_company --- False:MinMaxScaler; True:StandardScaler\n",
    "# wa: Work_accident --- False:MinMaxScaler; True:StandardScaler\n",
    "# pl5: promotion_last_5years --- False:MinMaxScaler; True:StandardScaler\n",
    "# dp: department --- False:LabelEncoder; True:OneHotEncoder\n",
    "# slr: salary --- False:LabelEncoder; True:OneHotEncoder\n",
    "def hr_preprocessing(sl=False, \n",
    "                     le=False, \n",
    "                     npr=False, \n",
    "                     amh=False, \n",
    "                     tsc=False, \n",
    "                     wa=False, \n",
    "                     pl5=False, \n",
    "                     dp=False, \n",
    "                     slr=False, \n",
    "                     lower_d=False, \n",
    "                     ld_n=1):\n",
    "    df = pd.read_csv('./data/HR.csv')\n",
    "    \n",
    "    ## 1. clean the data\n",
    "    #  remove the outliers\n",
    "    df = df.dropna(subset=['satisfaction_level', 'last_evaluation'])\n",
    "    df = df[df['satisfaction_level'] <= 1][df['salary']!='nme']\n",
    "    \n",
    "    ## 2. get the label\n",
    "    label = df['left']\n",
    "    df = df.drop('left', axis=1)\n",
    "\n",
    "    ## 3. feature selection\n",
    "    #  due to few features, we keep all the features\n",
    "    \n",
    "    ## 4. feature preprocessing\n",
    "    scaler_lst = [sl, le, npr, amh, tsc, wa, pl5]\n",
    "    column_lst = ['satisfaction_level', 'last_evaluation', 'number_project', \\\n",
    "                  'average_monthly_hours', 'time_spend_company', 'Work_accident', 'promotion_last_5years']\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            df[column_lst[i]] = \\\n",
    "                MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1, -1)[0]\n",
    "        else:\n",
    "            df[column_lst[i]] = \\\n",
    "                StandardScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1, -1)[0]\n",
    "    \n",
    "    scaler_lst = [dp, slr]\n",
    "    column_lst = ['department', 'salary']\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            if column_lst[i] == 'salary':\n",
    "                df[column_lst[i]] = [map_salary(s) for s in df['salary'].values]\n",
    "            else:\n",
    "                df[column_lst[i]] = LabelEncoder().fit_transform(df[column_lst[i]])\n",
    "            df[column_lst[i]] = \\\n",
    "                MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1, -1)[0]\n",
    "        else:\n",
    "            df = pd.get_dummies(df, columns=[column_lst[i]])\n",
    "    if lower_d:\n",
    "        #return LinearDiscriminantAnalysis(n_components=ld_n)\n",
    "        return PCA(n_components=ld_n).fit_transform(df.values)\n",
    "    return df, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict([('low', 0), ('medium', 1), ('high', 2)])\n",
    "def map_salary(s):\n",
    "    return d.get(s, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr_modeling(features, label):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    f_v = features.values\n",
    "    f_names = features.columns.values\n",
    "    l_v = label.values\n",
    "    X_tt, X_validation, Y_tt, Y_validation = train_test_split(f_v, l_v, test_size=0.2)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_tt, Y_tt, test_size=0.25)\n",
    "    \n",
    "    \n",
    "    ## KNN\n",
    "    from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "    from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "    from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "    from sklearn.externals.six import StringIO\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    \n",
    "    models = []\n",
    "    models.append(('KNN', KNeighborsClassifier(n_neighbors=3)))\n",
    "    models.append(('GaussianNB', GaussianNB()))\n",
    "    models.append(('BernoulliNB', BernoulliNB()))\n",
    "    models.append(('DecesionTreeGini', DecisionTreeClassifier()))\n",
    "    models.append(('DecesionTreeEntropy', DecisionTreeClassifier(criterion='entropy')))\n",
    "    models.append(('SVM Classifier', SVC(C=100)))\n",
    "    models.append(('RandomForest', RandomForestClassifier(max_features=None, bootstrap=False)))\n",
    "    models.append(('Adaboost', AdaBoostClassifier(n_estimators=100)))\n",
    "    \n",
    "    for clf_name, clf in models:\n",
    "        clf.fit(X_train, Y_train)\n",
    "        \n",
    "        xy_lst = [(X_train, Y_train), (X_validation, Y_validation),(X_test, Y_test)]\n",
    "        for i in range(len(xy_lst)):\n",
    "            X_part = xy_lst[i][0]\n",
    "            Y_part = xy_lst[i][1]\n",
    "            \n",
    "            Y_pred = clf.predict(X_part)\n",
    "            \n",
    "            print (i)\n",
    "            print (clf_name, '-ACC:',accuracy_score(Y_part, Y_pred))\n",
    "            print (clf_name, '-REC:',recall_score(Y_part, Y_pred))\n",
    "            print (clf_name, '-F1:',f1_score(Y_part, Y_pred))\n",
    "            \n",
    "            ### draw the Decision Tree\n",
    "            ## version 1\n",
    "#             dot_data = export_graphviz(clf, \n",
    "#                                        out_file=None, \n",
    "#                                        feature_names=f_names,\n",
    "#                                        class_names=['NL', 'L'], \n",
    "#                                        filled=True, \n",
    "#                                        rounded=True, \n",
    "#                                        special_characters=True)\n",
    "#             graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "#             graph.write_pdf('dt_tree.pdf')\n",
    "            \n",
    "            ## version 2\n",
    "#             dot_data = StringIO()\n",
    "#             export_graphviz(clf,\n",
    "#                             out_file=dot_data, \n",
    "#                             feature_names=f_names,\n",
    "#                             class_names=['NL', 'L'], \n",
    "#                             filled=True, \n",
    "#                             rounded=True, \n",
    "#                             special_characters=True)\n",
    "#             graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "#             graph.write_pdf('dt_tree_2.pdf')\n",
    "  \n",
    "    '''\n",
    "    ## save model\n",
    "    from sklearn.externals import joblib\n",
    "    joblib.dump(knn_clf, 'knn_clf')\n",
    "    ## use model\n",
    "    knn_clfjoblib.load('knn_clf')\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    features, label = hr_preprocessing()\n",
    "    hr_modeling(features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "KNN -ACC: 0.9761084564951661\n",
      "KNN -REC: 0.9632075471698113\n",
      "KNN -F1: 0.9499883693882297\n",
      "1\n",
      "KNN -ACC: 0.9563333333333334\n",
      "KNN -REC: 0.923728813559322\n",
      "KNN -F1: 0.9089645587213343\n",
      "2\n",
      "KNN -ACC: 0.9566666666666667\n",
      "KNN -REC: 0.9098250336473755\n",
      "KNN -F1: 0.912280701754386\n",
      "0\n",
      "GaussianNB -ACC: 0.7877541949105457\n",
      "GaussianNB -REC: 0.7410377358490566\n",
      "GaussianNB -F1: 0.6219319081551862\n",
      "1\n",
      "GaussianNB -ACC: 0.7913333333333333\n",
      "GaussianNB -REC: 0.7641242937853108\n",
      "GaussianNB -F1: 0.6334894613583139\n",
      "2\n",
      "GaussianNB -ACC: 0.7903333333333333\n",
      "GaussianNB -REC: 0.7617765814266487\n",
      "GaussianNB -F1: 0.6428165814877911\n",
      "0\n",
      "BernoulliNB -ACC: 0.8413157017446383\n",
      "BernoulliNB -REC: 0.46084905660377357\n",
      "BernoulliNB -F1: 0.5777646363098758\n",
      "1\n",
      "BernoulliNB -ACC: 0.835\n",
      "BernoulliNB -REC: 0.4519774011299435\n",
      "BernoulliNB -F1: 0.5638766519823789\n",
      "2\n",
      "BernoulliNB -ACC: 0.8493333333333334\n",
      "BernoulliNB -REC: 0.506056527590848\n",
      "BernoulliNB -F1: 0.6245847176079734\n",
      "0\n",
      "DecesionTreeGini -ACC: 1.0\n",
      "DecesionTreeGini -REC: 1.0\n",
      "DecesionTreeGini -F1: 1.0\n",
      "1\n",
      "DecesionTreeGini -ACC: 0.9753333333333334\n",
      "DecesionTreeGini -REC: 0.9505649717514124\n",
      "DecesionTreeGini -F1: 0.947887323943662\n",
      "2\n",
      "DecesionTreeGini -ACC: 0.9776666666666667\n",
      "DecesionTreeGini -REC: 0.9488559892328399\n",
      "DecesionTreeGini -F1: 0.9546377792823291\n",
      "0\n",
      "DecesionTreeEntropy -ACC: 1.0\n",
      "DecesionTreeEntropy -REC: 1.0\n",
      "DecesionTreeEntropy -F1: 1.0\n",
      "1\n",
      "DecesionTreeEntropy -ACC: 0.9766666666666667\n",
      "DecesionTreeEntropy -REC: 0.9548022598870056\n",
      "DecesionTreeEntropy -F1: 0.9507735583684951\n",
      "2\n",
      "DecesionTreeEntropy -ACC: 0.9813333333333333\n",
      "DecesionTreeEntropy -REC: 0.9542395693135935\n",
      "DecesionTreeEntropy -F1: 0.9620081411126188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "SVM Classifier -ACC: 0.9528836537393044\n",
      "SVM Classifier -REC: 0.9070754716981132\n",
      "SVM Classifier -F1: 0.9007025761124122\n",
      "1\n",
      "SVM Classifier -ACC: 0.955\n",
      "SVM Classifier -REC: 0.903954802259887\n",
      "SVM Classifier -F1: 0.9045936395759718\n",
      "2\n",
      "SVM Classifier -ACC: 0.9563333333333334\n",
      "SVM Classifier -REC: 0.8909825033647375\n",
      "SVM Classifier -F1: 0.9099656357388315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "RandomForest -ACC: 1.0\n",
      "RandomForest -REC: 1.0\n",
      "RandomForest -F1: 1.0\n",
      "1\n",
      "RandomForest -ACC: 0.9763333333333334\n",
      "RandomForest -REC: 0.9491525423728814\n",
      "RandomForest -F1: 0.9498233215547702\n",
      "2\n",
      "RandomForest -ACC: 0.9786666666666667\n",
      "RandomForest -REC: 0.9488559892328399\n",
      "RandomForest -F1: 0.9565807327001358\n",
      "0\n",
      "Adaboost -ACC: 0.9654406045116124\n",
      "Adaboost -REC: 0.9231132075471699\n",
      "Adaboost -F1: 0.9263905325443788\n",
      "1\n",
      "Adaboost -ACC: 0.9596666666666667\n",
      "Adaboost -REC: 0.9180790960451978\n",
      "Adaboost -F1: 0.9148486980999296\n",
      "2\n",
      "Adaboost -ACC: 0.9626666666666667\n",
      "Adaboost -REC: 0.8977119784656796\n",
      "Adaboost -F1: 0.9225449515905946\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
