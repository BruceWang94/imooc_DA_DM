{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sl: satisfaction_level --- False:MinMaxScaler; True:StandardScaler\n",
    "# le: last_evaluation --- False:MinMaxScaler; True:StandardScaler\n",
    "# npr: number_project --- False:MinMaxScaler; True:StandardScaler\n",
    "# amh: average_monthly_hours --- False:MinMaxScaler; True:StandardScaler\n",
    "# tsc: time_spend_company --- False:MinMaxScaler; True:StandardScaler\n",
    "# wa: Work_accident --- False:MinMaxScaler; True:StandardScaler\n",
    "# pl5: promotion_last_5years --- False:MinMaxScaler; True:StandardScaler\n",
    "# dp: department --- False:LabelEncoder; True:OneHotEncoder\n",
    "# slr: salary --- False:LabelEncoder; True:OneHotEncoder\n",
    "def hr_preprocessing(sl=False, \n",
    "                     le=False, \n",
    "                     npr=False, \n",
    "                     amh=False, \n",
    "                     tsc=False, \n",
    "                     wa=False, \n",
    "                     pl5=False, \n",
    "                     dp=False, \n",
    "                     slr=False, \n",
    "                     lower_d=False, \n",
    "                     ld_n=1):\n",
    "    df = pd.read_csv('./data/HR.csv')\n",
    "    \n",
    "    ## 1. clean the data\n",
    "    #  remove the outliers\n",
    "    df = df.dropna(subset=['satisfaction_level', 'last_evaluation'])\n",
    "    df = df[df['satisfaction_level'] <= 1][df['salary']!='nme']\n",
    "    \n",
    "    ## 2. get the label\n",
    "    label = df['left']\n",
    "    df = df.drop('left', axis=1)\n",
    "\n",
    "    ## 3. feature selection\n",
    "    #  due to few features, we keep all the features\n",
    "    \n",
    "    ## 4. feature preprocessing\n",
    "    scaler_lst = [sl, le, npr, amh, tsc, wa, pl5]\n",
    "    column_lst = ['satisfaction_level', 'last_evaluation', 'number_project', \\\n",
    "                  'average_monthly_hours', 'time_spend_company', 'Work_accident', 'promotion_last_5years']\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            df[column_lst[i]] = \\\n",
    "                MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1, -1)[0]\n",
    "        else:\n",
    "            df[column_lst[i]] = \\\n",
    "                StandardScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1, -1)[0]\n",
    "    \n",
    "    scaler_lst = [dp, slr]\n",
    "    column_lst = ['department', 'salary']\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            if column_lst[i] == 'salary':\n",
    "                df[column_lst[i]] = [map_salary(s) for s in df['salary'].values]\n",
    "            else:\n",
    "                df[column_lst[i]] = LabelEncoder().fit_transform(df[column_lst[i]])\n",
    "            df[column_lst[i]] = \\\n",
    "                MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1, -1)[0]\n",
    "        else:\n",
    "            df = pd.get_dummies(df, columns=[column_lst[i]])\n",
    "    if lower_d:\n",
    "        #return LinearDiscriminantAnalysis(n_components=ld_n)\n",
    "        return PCA(n_components=ld_n).fit_transform(df.values)\n",
    "    return df, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict([('low', 0), ('medium', 1), ('high', 2)])\n",
    "def map_salary(s):\n",
    "    return d.get(s, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr_modeling(features, label):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    f_v = features.values\n",
    "    l_v = label.values\n",
    "    X_tt, X_validation, Y_tt, Y_validation = train_test_split(f_v, l_v, test_size=0.2)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_tt, Y_tt, test_size=0.25)\n",
    "    \n",
    "    \n",
    "    ## KNN\n",
    "    from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "    from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "    \n",
    "    models = []\n",
    "    models.append(('KNN', KNeighborsClassifier(n_neighbors=3)))\n",
    "    models.append(('GaussianNB', GaussianNB()))\n",
    "    models.append(('BernoulliNB', BernoulliNB()))\n",
    "    \n",
    "    for clf_name, clf in models:\n",
    "        clf.fit(X_train, Y_train)\n",
    "        \n",
    "        xy_lst = [(X_train, Y_train), (X_validation, Y_validation),(X_test, Y_test)]\n",
    "        for i in range(len(xy_lst)):\n",
    "            X_part = xy_lst[i][0]\n",
    "            Y_part = xy_lst[i][1]\n",
    "            \n",
    "            Y_pred = clf.predict(X_part)\n",
    "            \n",
    "            print (i)\n",
    "            print (clf_name, '-ACC:',accuracy_score(Y_part, Y_pred))\n",
    "            print (clf_name, '-REC:',recall_score(Y_part, Y_pred))\n",
    "            print (clf_name, '-F1:',f1_score(Y_part, Y_pred))\n",
    "  \n",
    "    '''\n",
    "    ## save model\n",
    "    from sklearn.externals import joblib\n",
    "    joblib.dump(knn_clf, 'knn_clf')\n",
    "    ## use model\n",
    "    knn_clfjoblib.load('knn_clf')\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    features, label = hr_preprocessing()\n",
    "    hr_modeling(features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "KNN -ACC: 0.975330592288032\n",
      "KNN -REC: 0.9626477541371158\n",
      "KNN -F1: 0.9482999534233814\n",
      "1\n",
      "KNN -ACC: 0.9483333333333334\n",
      "KNN -REC: 0.9230769230769231\n",
      "KNN -F1: 0.8913805185704275\n",
      "2\n",
      "KNN -ACC: 0.956\n",
      "KNN -REC: 0.9361147327249022\n",
      "KNN -F1: 0.9158163265306122\n",
      "0\n",
      "GaussianNB -ACC: 0.8045338370930103\n",
      "GaussianNB -REC: 0.7252955082742317\n",
      "GaussianNB -F1: 0.6355914646778538\n",
      "1\n",
      "GaussianNB -ACC: 0.8033333333333333\n",
      "GaussianNB -REC: 0.7343976777939042\n",
      "GaussianNB -F1: 0.6317103620474406\n",
      "2\n",
      "GaussianNB -ACC: 0.7926666666666666\n",
      "GaussianNB -REC: 0.7131681877444589\n",
      "GaussianNB -F1: 0.6375291375291374\n",
      "0\n",
      "BernoulliNB -ACC: 0.845427269696633\n",
      "BernoulliNB -REC: 0.4723404255319149\n",
      "BernoulliNB -F1: 0.5895544408380053\n",
      "1\n",
      "BernoulliNB -ACC: 0.844\n",
      "BernoulliNB -REC: 0.46879535558780844\n",
      "BernoulliNB -F1: 0.5798922800718134\n",
      "2\n",
      "BernoulliNB -ACC: 0.8276666666666667\n",
      "BernoulliNB -REC: 0.46153846153846156\n",
      "BernoulliNB -F1: 0.5779591836734694\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
