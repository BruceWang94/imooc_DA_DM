{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sl: satisfaction_level --- False:MinMaxScaler; True:StandardScaler\n",
    "# le: last_evaluation --- False:MinMaxScaler; True:StandardScaler\n",
    "# npr: number_project --- False:MinMaxScaler; True:StandardScaler\n",
    "# amh: average_monthly_hours --- False:MinMaxScaler; True:StandardScaler\n",
    "# tsc: time_spend_company --- False:MinMaxScaler; True:StandardScaler\n",
    "# wa: Work_accident --- False:MinMaxScaler; True:StandardScaler\n",
    "# pl5: promotion_last_5years --- False:MinMaxScaler; True:StandardScaler\n",
    "# dp: department --- False:LabelEncoder; True:OneHotEncoder\n",
    "# slr: salary --- False:LabelEncoder; True:OneHotEncoder\n",
    "def hr_preprocessing(sl=False, \n",
    "                     le=False, \n",
    "                     npr=False, \n",
    "                     amh=False, \n",
    "                     tsc=False, \n",
    "                     wa=False, \n",
    "                     pl5=False, \n",
    "                     dp=False, \n",
    "                     slr=False, \n",
    "                     lower_d=False, \n",
    "                     ld_n=1):\n",
    "    df = pd.read_csv('./data/HR.csv')\n",
    "    \n",
    "    ## 1. clean the data\n",
    "    #  remove the outliers\n",
    "    df = df.dropna(subset=['satisfaction_level', 'last_evaluation'])\n",
    "    df = df[df['satisfaction_level'] <= 1][df['salary']!='nme']\n",
    "    \n",
    "    ## 2. get the label\n",
    "    label = df['left']\n",
    "    df = df.drop('left', axis=1)\n",
    "\n",
    "    ## 3. feature selection\n",
    "    #  due to few features, we keep all the features\n",
    "    \n",
    "    ## 4. feature preprocessing\n",
    "    scaler_lst = [sl, le, npr, amh, tsc, wa, pl5]\n",
    "    column_lst = ['satisfaction_level', 'last_evaluation', 'number_project', \\\n",
    "                  'average_monthly_hours', 'time_spend_company', 'Work_accident', 'promotion_last_5years']\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            df[column_lst[i]] = \\\n",
    "                MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1, -1)[0]\n",
    "        else:\n",
    "            df[column_lst[i]] = \\\n",
    "                StandardScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1, -1)[0]\n",
    "    \n",
    "    scaler_lst = [dp, slr]\n",
    "    column_lst = ['department', 'salary']\n",
    "    for i in range(len(scaler_lst)):\n",
    "        if not scaler_lst[i]:\n",
    "            if column_lst[i] == 'salary':\n",
    "                df[column_lst[i]] = [map_salary(s) for s in df['salary'].values]\n",
    "            else:\n",
    "                df[column_lst[i]] = LabelEncoder().fit_transform(df[column_lst[i]])\n",
    "            df[column_lst[i]] = \\\n",
    "                MinMaxScaler().fit_transform(df[column_lst[i]].values.reshape(-1,1)).reshape(1, -1)[0]\n",
    "        else:\n",
    "            df = pd.get_dummies(df, columns=[column_lst[i]])\n",
    "    if lower_d:\n",
    "        #return LinearDiscriminantAnalysis(n_components=ld_n)\n",
    "        return PCA(n_components=ld_n).fit_transform(df.values)\n",
    "    return df, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict([('low', 0), ('medium', 1), ('high', 2)])\n",
    "def map_salary(s):\n",
    "    return d.get(s, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr_modeling(features, label):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    f_v = features.values\n",
    "    l_v = label.values\n",
    "    X_tt, X_validation, Y_tt, Y_validation = train_test_split(f_v, l_v, test_size=0.2)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_tt, Y_tt, test_size=0.25)\n",
    "    \n",
    "    \n",
    "    ## KNN\n",
    "    from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "    \n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn_clf_n5 = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_clf.fit(X_train, Y_train)\n",
    "    knn_clf_n5.fit(X_train, Y_train)\n",
    "    \n",
    "   \n",
    "    \n",
    "    from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "    \n",
    "    Y_pred = knn_clf.predict(X_train)\n",
    "    print (\"Train:\")\n",
    "    print ('ACC:', accuracy_score(Y_train, Y_pred))\n",
    "    print ('REC:', recall_score(Y_train, Y_pred))\n",
    "    print ('F-score:', f1_score(Y_train, Y_pred))\n",
    "    \n",
    "    Y_pred = knn_clf.predict(X_validation)\n",
    "    print ('\\nValidation:')\n",
    "    print ('ACC:', accuracy_score(Y_validation, Y_pred))\n",
    "    print ('REC:', recall_score(Y_validation, Y_pred))\n",
    "    print ('F-score:', f1_score(Y_validation, Y_pred))\n",
    "    \n",
    "    Y_pred_n5 = knn_clf_n5.predict(X_validation)\n",
    "    print ('ACC:', accuracy_score(Y_validation, Y_pred_n5))\n",
    "    print ('REC:', recall_score(Y_validation, Y_pred_n5))\n",
    "    print ('F-score:', f1_score(Y_validation, Y_pred_n5))\n",
    "    \n",
    "    Y_pred = knn_clf.predict(X_test)\n",
    "    print ('\\nX_test:')\n",
    "    print ('ACC:', accuracy_score(Y_test, Y_pred))\n",
    "    print ('REC:', recall_score(Y_test, Y_pred))\n",
    "    print ('F-score:', f1_score(Y_test, Y_pred))\n",
    "    \n",
    "    ## save model\n",
    "    from sklearn.externals import joblib\n",
    "    joblib.dump(knn_clf, 'knn_clf')\n",
    "    ## use model\n",
    "    knn_clfjoblib.load('knn_clf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    features, label = hr_preprocessing()\n",
    "    hr_modeling(features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/shiyuwang/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "ACC: 0.9755528392043561\n",
      "REC: 0.9673413063477461\n",
      "F-score: 0.9502937189335742\n",
      "\n",
      "Validation:\n",
      "ACC: 0.9506666666666667\n",
      "REC: 0.921090387374462\n",
      "F-score: 0.8966480446927375\n",
      "ACC: 0.9513333333333334\n",
      "REC: 0.9053084648493543\n",
      "F-score: 0.8963068181818182\n",
      "\n",
      "X_test:\n",
      "ACC: 0.9546666666666667\n",
      "REC: 0.9385714285714286\n",
      "F-score: 0.9062068965517243\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
