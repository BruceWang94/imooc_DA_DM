# 4.分析建模

## 机器学习与建模

- 学习：通过接收到的数据，归纳提取相同与不同。
- 机器学习：让计算机以数据为基础，进行归纳与总结。
- 模型：数据解释现象的系统。

机器学习根据是否有标注可以分为：
- 监督学习

    有标注的机器学习过程。

    - 分类 - 标注是离散值
    - 回归 - 标注是连续值
- 非监督学习

    没有标注的机器学习过程。

    - 聚类分析
    - 关联分析
- 半监督学习

    部分有标注，部分没有标注。

## 训练集、测试集、验证集

- 训练集：用来训练和拟合模型
- 验证集：当通过训练集训练出多个模型后，使用验证集数据纠偏或比较预测
- 测试集：模型繁华能力的考量

泛化能力：对位置数据的预测能力。
k-fold交叉验证：将数据集分成K份，没分轮流做一遍测试集，其他做训练集。

## 分类

- KNN
- 朴素贝叶斯
- 决策时
- 支持向量机
- 集成方法
- 罗基斯特映射
- 人工神经网络

### KNN（K-Nearest Neighbors）

#### 距离

- 欧式距离

    $$d_{12} = \sqrt{\sum_{k=1}^{n}{(x_{1k} - x_{2k})^2}}$$
- 曼哈顿距离

    $$d_{12} = \sum_{k=1}^{n}{|x_{1k} - x_{2k}|}$$
- 闵可夫斯基距离

    $$d_{12} = \sqrt[p]{\sum_{k=1}^{n}{|x_{1k} - x_{2k}|^p})}$$

#### KD-Tree

通过树形结构

#### 算法思想

### 朴素贝叶斯

- 概率：$P(A)$
- 条件概率：$P(A|B)$， 联合概率：$P(A,B)$

    例如：有5个球，2个白球，3个红球</br>
    随机抽一个球，红球的概率：

    $$P(抽到红球)=3/5$$
    不放回抽，第一次抽到红球，第二次抽到红球的概率：

    $$P(第二次红|第一次红)=2/4，P(第一次红, 第二次红)=6/10$$

- $P(A,B)=P(A|B)P(B)=P(B|A)P(A)$
- 全概率公式：$P(B)=\sum{P(A_i)P(B|A_i)}$
- 贝叶斯公式：$P(B_i|A)=\frac{P(B_i)P(A|B_i)}{\sum{P(B_i)P(A|B_i)}}$

    例如：有5个球，2个白球，3个红球</br>
    抽两次，第二次抽到红球的概率：

    $$P(二红) = P(一白)P(二红|一白) + P(一红)P(二红|一红) = 2/5*3/4 + 3/5*2/4 = 3/5$$

- 例：
    某SNS网站的10000个样本中，真实账号比例$C0=0.89$，虚假账号比例$C1=0.11$。</br>
    $F1$：日志数量/注册天数 $F2<=0.05$, $0.05<F2<0.2$, $F2>0.2$</br>
    $F2$：好友数量/注册天数 $F2<=0.1$, $0.1<F2<0.8$, $F2>0.8$</br>
    $F3$：是否使用真实头像（真实头像为1，非真实头像为0）

    账户状态：$F1=1$（指落入区间1）, $F2=1$, $F3=0$ </br>
    已知条件：</br>
    $P(F1=1|C0)=0.5$，$P(F1=0|C0)=0.5$ </br>
    $P(F2=1|C0)=0.7$，$P(F2=0|C0)=0.2$ </br>
    $P(F3=1|C0)=0.2$，$P(F3=0|C0)=0.9$ </br>

    $$
    \begin{aligned}
    P(C|F1=1, F2=1, F3=0) & = \frac{P(F1=1, F2=1, F3=0|C)P(C)} {P(F1=1, F2=1, F3=0)} \\\\
                          & = \frac{P(F1=1|C)P(F2=1|C)P(F3=0|C)P(C)} {P(F1=1, F2=1, F3=0)}
    \end{aligned}
    $$

    所以：</br>
    $P(F1=1|C0)P(F2=1|C0)P(F3=0|C0)P(C0) = 0.5*0.7*0.2*0.89=0.0623$ </br>
    $P(F1=1|c1)P(F2=1|c1)P(F3=0|c1)P(c1) = 0.1*0.2*0.2*0.11=0.00198$

- Laplace平滑

#### 生成模型与判别模型

- 生成模型：通过求输入与输出的联合概率分布，再求解类别归类的概率。

    $$P(B|A) = \frac{P(A|B)P(B)}{P(A)}$$

- 判别模型：不通过联合概率分布，直接可以可以获得输出对应最大分类的概率。

### 决策树

<table>
    <tr>
        <td align='center'>No.</td>
        <td align='center'>Outlook</td>
        <td align='center'>Temperature</td>
        <td align='center'>Humidity</td>
        <td align='center'>Wind</td>
        <td align='center'>Play</td>
    </tr>
    <tr>
        <td align='center'>1</td>
        <td align='center'>Sunny</td>
        <td align='center'>Hot</td>
        <td align='center'>High</td>
        <td align='center'>Weak</td>
        <td align='center'>No</td>
    </tr>
    <tr>
        <td align='center'>2</td>
        <td align='center'>Sunny</td>
        <td align='center'>Hot</td>
        <td align='center'>High</td>
        <td align='center'>strong</td>
        <td align='center'>No</td>
    </tr>
    <tr>
        <td align='center'>3</td>
        <td align='center'>Overcast</td>
        <td align='center'>Hot</td>
        <td align='center'>High</td>
        <td align='center'>Weak</td>
        <td align='center'>Yes</td>
    </tr>
    <tr>
        <td align='center'>4</td>
        <td align='center'>Rain</td>
        <td align='center'>Mild</td>
        <td align='center'>High</td>
        <td align='center'>Weak</td>
        <td align='center'>Yes</td>
    </tr>
    <tr>
        <td align='center'>5</td>
        <td align='center'>Rain</td>
        <td align='center'>Cool</td>
        <td align='center'>Normal</td>
        <td align='center'>Weak</td>
        <td align='center'>Yes</td>
    </tr>
    <tr>
        <td align='center'>6</td>
        <td align='center'>Rain</td>
        <td align='center'>Cool</td>
        <td align='center'>Normal</td>
        <td align='center'>Strong</td>
        <td align='center'>No</td>
    </tr>
    <tr>
        <td align='center'>7</td>
        <td align='center'>Overcast</td>
        <td align='center'>Cool</td>
        <td align='center'>Normal</td>
        <td align='center'>Strong</td>
        <td align='center'>Yes</td>
    </tr>
    <tr>
        <td align='center'>8</td>
        <td align='center'>Sunny</td>
        <td align='center'>Mild</td>
        <td align='center'>High</td>
        <td align='center'>Weak</td>
        <td align='center'>No</td>
    </tr>
    <tr>
        <td align='center'>9</td>
        <td align='center'>Sunny</td>
        <td align='center'>Cool</td>
        <td align='center'>Normal</td>
        <td align='center'>Weak</td>
        <td align='center'>Yes</td>
    </tr>
    <tr>
        <td align='center'>10</td>
        <td align='center'>Rain</td>
        <td align='center'>Mild</td>
        <td align='center'>Normal</td>
        <td align='center'>Weak</td>
        <td align='center'>Yes</td>
    </tr>
    <tr>
        <td align='center'>11</td>
        <td align='center'>Sunny</td>
        <td align='center'>Mild</td>
        <td align='center'>Normal</td>
        <td align='center'>Strong</td>
        <td align='center'>Yes</td>
    </tr>
    <tr>
        <td align='center'>12</td>
        <td align='center'>Overcast</td>
        <td align='center'>Mild</td>
        <td align='center'>High</td>
        <td align='center'>Strong</td>
        <td align='center'>Yes</td>
    </tr>
    <tr>
        <td align='center'>13</td>
        <td align='center'>Overcast</td>
        <td align='center'>Hot</td>
        <td align='center'>Normal</td>
        <td align='center'>Weak</td>
        <td align='center'>Yes</td>
    </tr>
    <tr>
        <td align='center'>14</td>
        <td align='center'>Rain</td>
        <td align='center'>Mild</td>
        <td align='center'>High</td>
        <td align='center'>Strong</td>
        <td align='center'>No</td>
    </tr>
</table>

- 信息增益-ID3

    $H(X) = - \sum{p_i\log(p_i)}$

    $I(X,Y) = H(Y) - H(Y|X) = H(X) - H(X|Y)$

    例如上例中：
    
    $Entropy(S) = -(9/14) * \log(9/14) - (5/14)*\log(5/14)$

    按Wind切分：

    $$
    \begin{aligned}
    Gain(Wind) & = Entropy(S) - (8/14) * Entropy(Weak) - (6/14) * Entropy(Strong) \\\\
    & = 0.940 - (8/14) * 0.811 - (6/14) * 1.0 \\\\
    & = 0.048
    \end{aligned}
    $$

    同时，$Gain(Humidity)=0.151$，$Gain(Outlook)=0.247$，$Gain(Temperature)=0.029$。
    得到Outlook的增益是最大的，所以按Outlook切分。

- 信息增益率-C4.5

    $GainRatio(X \to Y) = \frac{I(X,Y)}{H(Y)}$

    $GainRation(Outlook) = 0.247/(-4/14*\log(4/14) - 5/14*\log(5/14) - 5/14*\log(5/14)) = 0.156$

- Gini系数-CART

    $Gini(D) = 1 - \sum{(\frac{C_k}{D})^2}$

    Humidity:

    $Gini(High) = 1 - [(3/7)^2 + (4/7)^2] = 0.490$

    $Gini(Normal) = 1 - [(1/7)^2 + (6/7)^2] = 0.345$

    所以

    $Gini(Humidity) = 7/14 * 0.490 + 7/14 * 0.245 = 0.368$

有以下几个问题需要注意：

- 连续值切分 - 计算每个分隔
- 规则用尽 - 投票
- 过拟合 - 修枝剪叶
    - 前剪枝
    - 后剪枝

### 支持向量机

### 集成-随机僧领

### 集成-Adaboost
## 回归
### 线性回归
### 逻辑回归
### 人工神经网络
### 回归树与提升树
## 聚类
### Kmeans
### DBSCAN
### 层次聚类
### 图分裂
## 关联
### 关联规则
## 半监督-标签传播算法

